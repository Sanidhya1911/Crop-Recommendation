# -*- coding: utf-8 -*-
"""Crop recommendation final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/190SrqLn_3ZsZ9mLInCvcZQ2r4z5JFzav

# Business Understanding and Problem Framing

- Farming holds the biggest stakes in the global market.
- There are approximately 570 million farms worldwide, varying significantly in size and productivity.
- Farm size matters for economic development, poverty alleviation, global food production, and environmental impacts.
- Over the past few decades, global crop production has seen significant changes.
- Environmental changes and unorthodox changes in the climate has affected the global farming.
- There are facilities freely available for farmers to get best assitance but lack of awareness among the farmers is the biggest issues
- we are countering this issue by creating a Machine Learning Model which predicts and Recommend the best crop suitable to grow based on the previously available trained data.

# Data Collection and Preprocessing
"""

#importing warnings library to avoid warnings
import warnings
warnings.filterwarnings('ignore',category=FutureWarning)

import pandas as pd

data1 = pd.read_csv('datasets/Crop_data1.csv')
data1.head()

data2 = pd.read_csv('datasets/Crop_data2.csv')
data2.head()

#sanity checkp
data1.info()

data2.info()

#calculating shape of columns
data1.shape

data2.shape

#finding missing value
data1.isnull().sum()

data2.isnull().sum()

#finding duplicates
data1.duplicated().sum()

data2.duplicated().sum()

data2.drop_duplicates(subset = ['N','P','K','temperature','humidity','ph','rainfall'],keep = 'first',inplace = True)
data2.duplicated().sum()

#identifiying Garbage values
for i in data1.select_dtypes(include = 'object').columns:
    print(data1[i].value_counts())
    print("***"*10)

for i in data2.select_dtypes(include = 'object').columns:
    print(data2[i].value_counts())
    print("***"*10)

"""# Exploratory Data Analysis

we are using the datasets which contains the features named as _[N,P,K,temperature,humidity,ph,rainfall,label]_ for training the model.
"""

#descriptive statistics
data1.describe()

#transposing the data
data1.describe().T

data2.describe()

data2.describe().T

#descriptive statistics of object column
data1.describe(include = 'object')

data2.describe(include = 'object')

#histogram to understand the distribution
import seaborn as sns
from matplotlib import pyplot as plt
for i in data1.select_dtypes(include = ['number']).columns:
    sns.histplot(data = data1,x=i)
    plt.show()

for i in data2.select_dtypes(include = 'number').columns:
    sns.histplot(data = data2,x=i)
    plt.show()

"""### Calculating Z-scores to check the outliers"""

from scipy import stats
import numpy as np
z_scores = stats.zscore(data1.select_dtypes(include=['number']))
abs_z_scores = np.abs(z_scores)
outliers = (abs_z_scores > 3).any(axis=1)
data1_outliers = data1[outliers]
print(data1_outliers)

"""### function to check the quantile values for classifying outliers"""

def whisker(col):
    q1,q3 = np.percentile(col,[25,75])
    iqr = q3-q1
    lw = q1 - 1.5 * iqr
    uw = q1 + 1.5 * iqr
    return lw,uw

for i in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
    lw,uw = whisker(data1[i])
    print(f'\t\t\tOutliers\n*****************************************************************************************')
    print(f'{i}-lower:{lw}\t\t{i}-upper:{uw}\n')
    # outliers = ((data1[i] < (lw)) | (data1[i] > (uw)))
    # data1_outliers = data1[outliers]
    # print(data1_outliers)

#box plot to identify the distribution and outliers
import seaborn as sns
from matplotlib import pyplot as plt
for i in data1.select_dtypes(include = ['number']).columns:
    sns.boxplot(data = data1,x=i)
    plt.show()

from scipy import stats
import numpy as np
z_scores = stats.zscore(data2.select_dtypes(include=['number']))
abs_z_scores = np.abs(z_scores)
outliers = (abs_z_scores > 3).any(axis=1)
data2_outliers = data2[outliers]
print(data2_outliers)

for i in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
    lw,uw = whisker(data2[i])
    print(f'\t\t\tOutliers\n*****************************************************************************************')
    print(f'{i}-lower:{lw}\t\t{i}-upper:{uw}\n')
    # outliers = ((data1[i] < (lw)) | (data1[i] > (uw)))
    # data1_outliers = data1[outliers]
    # print(data1_outliers)

for i in data2.select_dtypes(include = 'number').columns:
    sns.boxplot(data = data2,x=i)
    plt.show()

#scatter plot to understand the realationship between features and label
for i in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
    sns.scatterplot(data = data1,x = i,y = 'label')
    plt.show()

for i in ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']:
    sns.scatterplot(data = data2,x = i,y = 'label')
    plt.show()

#correlation with heatmap to interpret the relation and multicolliniarity
set1 = data1.select_dtypes(include = 'number').corr()

set1

plt.figure(figsize = (10,8))
sns.heatmap(set1,annot=True,fmt='.2f',cmap = 'coolwarm')
plt.title('correlation matrix')

set2 = data2.select_dtypes(include = 'number').corr()

set2

plt.figure(figsize = (10,8))
sns.heatmap(set2,annot=True,fmt='.2f',cmap = 'coolwarm')
plt.title('correlation matrix')

data1.select_dtypes(include = 'number').columns

data2.select_dtypes(include = 'number').columns

"""# Feature Engineering

we are merging multiple datasets for better training and performance of the model
"""

# Merging datasets
import pandas as pd

df1 = pd.read_csv('datasets/Crop_data1.csv')
df1.head()

df2 = pd.read_csv('datasets/crop_data2.csv')
df2.head()

display(df1.shape,df2.shape)

merged_data = pd.concat([df1,df2],axis = 0)
merged_data.shape

merged_data

# checking fro duplicated values
merged_data.duplicated().sum()

# checking for null values
merged_data.isnull().sum()

# Removing duplicates
merged_data.drop_duplicates(subset = ['N','P','K','temperature','humidity','ph','rainfall'],keep = 'first',inplace = True)

merged_data.duplicated().sum()

final_dataset = merged_data

final_dataset

"""# Modelling process"""

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics

#load the datasets
data = final_dataset

data

data.head()

data.info()

data.describe()

data.shape

data.duplicated().sum()

# Selecting continuous numerical columns and the label
features = data.select_dtypes(include=[float, int]).columns
target = 'label'

# Splitting dataset as features and label
X = data[features]
y = data[target]

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the dataset using standard scaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# X_train_scaled = pd.DataFrame(X_train_scaled, columns = features)
# X_test_scaled = pd.DataFrame(X_test_scaled, columns = features)

display(X_train_scaled,X_test_scaled)

# Model Initializing using Gaussian NaiveBayes algorithm
model = GaussianNB()
model.fit(X_train_scaled, y_train)

# Making predictions
y_pred = model.predict(X_test_scaled)

# Function to predict crop using scaeled data
def predict_crop(features):
    features_df = pd.DataFrame([features], columns=features.keys())
    scaled_features = scaler.transform(features_df)
    prediction = model.predict(scaled_features)
    return prediction[0]

#input features
features = {
    'N': input('enter Nitrogen value:'),
    'P': input('Enter Phosphorous values:'),
    'K': input('Enter Potassium value:'),
    'temperature': input('Enter the Temperature:'),
    'humidity': input('Enter the Humidity:'),
    'ph': input('Enter the pH value:'),
    'rainfall': input('Enter the Rainfall')
}
print('Naive Bayes Prediction:', predict_crop(features))

"""# Model Evaluation"""

#importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the dataset
df = merged_data

# Selecting continuous columns and the label
continuous_columns = df.select_dtypes(include=[float, int]).columns
label_column = 'label'

# Splitting features and label
X = df[continuous_columns]
y = df[label_column]

# Splitting the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initializing the scaler
scaler = StandardScaler()

# Fitting the scaler on the training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# revertng the scaled array back to DataFrame to retain feature names
X_train_scaled = pd.DataFrame(X_train_scaled, columns=continuous_columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=continuous_columns)

# Model initializing using Gaussian Naive Bayes algorithm
model = GaussianNB()
model.fit(X_train_scaled, y_train)

# Predicting using the test data
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

# Calculating accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Training Accuracy: {train_accuracy*100}")
print(f"Test Accuracy: {test_accuracy*100}")

# Plot learning curves
train_sizes = np.linspace(0.1, 1.0, 10, endpoint=False)
train_scores = []
test_scores = []

for train_size in train_sizes:
    # Using only  portion of the training data
    X_train_partial, _, y_train_partial, _ = train_test_split(X_train_scaled, y_train, train_size=train_size, random_state=42)
    model.fit(X_train_partial, y_train_partial)
    train_scores.append(model.score(X_train_partial, y_train_partial))
    test_scores.append(model.score(X_test_scaled, y_test))

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores, label='Training Score')
plt.plot(train_sizes, test_scores, label='Validation Score')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score

# Training the model on training data
model.fit(X_train_scaled, y_train)

# Evaluating the model on training data
train_predictions = model.predict(X_train_scaled)
nb_train_accuracy = accuracy_score(y_train, train_predictions)
print(f'Training Accuracy: {nb_train_accuracy*100}')

# Evaluating the model on testing data
test_predictions = model.predict(X_test_scaled)
nb_test_accuracy = accuracy_score(y_test, test_predictions)
print(f'Test Accuracy: {nb_test_accuracy*100}')

from sklearn.model_selection import cross_val_score

# Performing cross-validation for model optimization
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
print(f'Cross-Validation Scores: {cv_scores*100}')
print(f'Mean CV Score: {cv_scores.mean()*100}')

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(model, X_train_scaled, y_train, cv=5,
                                                        train_sizes=np.linspace(0.1, 1.0, 10),
                                                        scoring='accuracy')

# Calculating mean and standard deviation
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')
plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')

plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color='r')
plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color='g')

plt.xlabel('Training Size')
plt.ylabel('Score')
plt.title('Learning Curves')
plt.legend(loc='best')
plt.show()

# Model Evaluation
from sklearn import metrics
accuracy = metrics.accuracy_score(y_test, y_pred)
precision = metrics.precision_score(y_test,y_pred,average = 'weighted',zero_division=0)
recall = metrics.recall_score(y_test,y_pred,average = 'weighted')
f1 = metrics.f1_score(y_test,y_pred,average = 'weighted')
print(f'Model Accuracy: {accuracy * 100:.2f}%')
print(f'Precision Score: {precision * 100:.2f}%')
print(f'Recall Score: {recall * 100: .2f}%')
print(f'f1-score: {f1*100:.2f}%')

cm = metrics.confusion_matrix(y_test,y_pred)
print(f'Confusion matrix:\n{cm}')
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

cr = metrics.classification_report(y_test,y_pred,zero_division=0)
print(f'Classification Report:\n{cr}')

"""# Insights and Recommendations"""

#training of data and checking libraries with more accuracy
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score


#libraries used in dictionary format
models = {
    'Logistic Regression' : LogisticRegression(),
    'Naive Bayes' : GaussianNB(),
    'Support Vector Machine' : SVC(),
    'K-Nearest Neighbors' : KNeighborsClassifier(),
    'Decision Tree' : DecisionTreeClassifier(),
    'Random Forest' : RandomForestClassifier(),
    'Bagging' : BaggingClassifier(),
    'AdaBoost' : AdaBoostClassifier(),
    'Gradient Boosting' : GradientBoostingClassifier(),
    'Extra Trees': ExtraTreeClassifier(),
}

#name = libraries/modulesnames, md = models dictionary and results will be assigned in items
for name,md in models.items():
    md.fit(X_train_scaled,y_train)
    ypred = md.predict(X_test_scaled)

    print(f"{name} with accuracy : {accuracy_score(y_test,ypred) * 100}")

"""# Modelling using SVM Classifier"""

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn import metrics

# Load the dataset
data = final_dataset

# Selecting continuous numerical columns and the label
features = data.select_dtypes(include=[float, int]).columns
target = 'label'

# Splitting dataset into features and label
X = data[features]
y = data[target]

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the dataset using standard scaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# model initializing using svm classifier
model = SVC(kernel='linear', random_state=42)
model.fit(X_train_scaled, y_train)

# Making predictions
y_pred = model.predict(X_test_scaled)

# Function to predict crop recommendation
def predict_crop(features):
    features_df = pd.DataFrame([features], columns=features.keys())
    scaled_features = scaler.transform(features_df)
    prediction = model.predict(scaled_features)
    return prediction[0]

#input features
features = {
    'N': input('enter Nitrogen value:'),
    'P': input('Enter Phosphorous values:'),
    'K': input('Enter Potassium value:'),
    'temperature': input('Enter the Temperature:'),
    'humidity': input('Enter the Humidity:'),
    'ph': input('Enter the pH value:'),
    'rainfall': input('Enter the Rainfall')
}
print('Naive Bayes Prediction:', predict_crop(features))

"""# SVM Classifier Evaluation"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the dataset
df = merged_data

# Selecting continuous columns and the label
continuous_columns = df.select_dtypes(include=[float, int]).columns
label_column = 'label'

# Splitting features and label
X = df[continuous_columns]
y = df[label_column]

# Splitting the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initializing the scaler
scaler = StandardScaler()

# Fitting the scaler on the training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# reverting back to DataFrame to retain feature names
X_train_scaled = pd.DataFrame(X_train_scaled, columns=continuous_columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=continuous_columns)

# Initializing and train the Naive Bayes Classifier
model = SVC()
model.fit(X_train_scaled, y_train)

# Predicting using the test data
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

# Calculating accuracy
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Training Accuracy: {train_accuracy*100}")
print(f"Test Accuracy: {test_accuracy*100}")

# Plottting learning curves
train_sizes = np.linspace(0.1, 1.0, 10, endpoint=False)
train_scores = []
test_scores = []

for train_size in train_sizes:
    # Using a portion of the training data
    X_train_partial, _, y_train_partial, _ = train_test_split(X_train_scaled, y_train, train_size=train_size, random_state=42)
    model.fit(X_train_partial, y_train_partial)
    train_scores.append(model.score(X_train_partial, y_train_partial))
    test_scores.append(model.score(X_test_scaled, y_test))

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores, label='Training Score')
plt.plot(train_sizes, test_scores, label='Validation Score')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score

# Training the model on training data
model.fit(X_train_scaled, y_train)

# Evaluating the model on training data
train_predictions =model.predict(X_train_scaled)
svm_train_accuracy = accuracy_score(y_train, train_predictions)
print(f'Training Accuracy: {svm_train_accuracy*100}')

# Evaluating the model on test data
test_predictions = model.predict(X_test_scaled)
svm_test_accuracy = accuracy_score(y_test, test_predictions)
print(f'Test Accuracy: {svm_test_accuracy*100}')

from sklearn.model_selection import cross_val_score

# Performing cross-validation
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
print(f'Cross-Validation Scores: {cv_scores*100}')
print(f'Mean CV Score: {cv_scores.mean()*100}')

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(model, X_train_scaled, y_train, cv=5,
                                                        train_sizes=np.linspace(0.1, 1.0, 10),
                                                        scoring='accuracy')

# Calculating mean and standard deviation
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')
plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')

plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color='r')
plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color='g')

plt.xlabel('Training Size')
plt.ylabel('Score')
plt.title('Learning Curves')
plt.legend(loc='best')
plt.show()

# Model Evaluation
from sklearn import metrics
accuracy = metrics.accuracy_score(y_test, y_pred)
precision = metrics.precision_score(y_test,y_pred,average = 'weighted',zero_division=0)
recall = metrics.recall_score(y_test,y_pred,average = 'weighted')
f1 = metrics.f1_score(y_test,y_pred,average = 'weighted')
print(f'Model Accuracy: {accuracy * 100:.2f}%')
print(f'Precision Score: {precision * 100:.2f}%')
print(f'Recall Score: {recall * 100: .2f}%')
print(f'f1-score: {f1*100:.2f}%')

cm = metrics.confusion_matrix(y_test,y_pred)
print(f'Confusion matrix:\n{cm}')
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

cr = metrics.classification_report(y_test,y_pred,zero_division=0)
print(f'Classification Report:\n{cr}')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the dataset
df = merged_data

# Select continuous columns and the label
continuous_columns = df.select_dtypes(include=[float, int]).columns
label_column = 'label'

# Split features and label
X = df[continuous_columns]
y = df[label_column]

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Convert back to DataFrame to retain feature names
X_train_scaled = pd.DataFrame(X_train_scaled, columns=continuous_columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=continuous_columns)

# Initialize and train the SVM Classifier
svm_clf = SVC(kernel='linear', random_state=42)
svm_clf.fit(X_train_scaled, y_train)

# Predict using the SVM model
y_train_pred_svm = svm_clf.predict(X_train_scaled)
y_test_pred_svm = svm_clf.predict(X_test_scaled)

# Calculate SVM accuracy
train_accuracy_svm = accuracy_score(y_train, y_train_pred_svm)
test_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)

print(f"SVM Training Accuracy: {train_accuracy_svm}")
print(f"SVM Test Accuracy: {test_accuracy_svm}")

# Initialize and train the Naive Bayes Classifier
nb_clf = GaussianNB()
nb_clf.fit(X_train_scaled, y_train)

# Predict using the Naive Bayes model
y_train_pred_nb = nb_clf.predict(X_train_scaled)
y_test_pred_nb = nb_clf.predict(X_test_scaled)

# Calculate Naive Bayes accuracy
train_accuracy_nb = accuracy_score(y_train, y_train_pred_nb)
test_accuracy_nb = accuracy_score(y_test, y_test_pred_nb)

print(f"Naive Bayes Training Accuracy: {train_accuracy_nb}")
print(f"Naive Bayes Test Accuracy: {test_accuracy_nb}")

# Plotting the accuracies
labels = ['SVM', 'Naive Bayes']
train_accuracies = [train_accuracy_svm, train_accuracy_nb]
test_accuracies = [test_accuracy_svm, test_accuracy_nb]

x = np.arange(len(labels))  # the label locations
width = 0.35

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')
rects2 = ax.bar(x + width/2, test_accuracies, width, label='Test Accuracy')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_xlabel('Model')
ax.set_ylabel('Accuracy')
ax.set_title('Accuracy Comparison between SVM and Naive Bayes')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

# Attach a text label above each bar in *rects*, displaying its height.
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate('{}'.format(round(height, 2)),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

fig.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the dataset
df = merged_data

# Select continuous columns and the label
continuous_columns = df.select_dtypes(include=[float, int]).columns
label_column = 'label'

# Split features and label
X = df[continuous_columns]
y = df[label_column]

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Convert back to DataFrame to retain feature names
X_train_scaled = pd.DataFrame(X_train_scaled, columns=continuous_columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=continuous_columns)

# Initialize and train the SVM Classifier
svm_clf = SVC(kernel='linear', random_state=42)
svm_clf.fit(X_train_scaled, y_train)

# Predict using the SVM model
y_train_pred_svm = svm_clf.predict(X_train_scaled)
y_test_pred_svm = svm_clf.predict(X_test_scaled)

# Calculate SVM accuracy
train_accuracy_svm = accuracy_score(y_train, y_train_pred_svm)
test_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)

print(f"SVM Training Accuracy: {train_accuracy_svm}")
print(f"SVM Test Accuracy: {test_accuracy_svm}")

# Initialize and train the Naive Bayes Classifier
nb_clf = GaussianNB()
nb_clf.fit(X_train_scaled, y_train)

# Predict using the Naive Bayes model
y_train_pred_nb = nb_clf.predict(X_train_scaled)
y_test_pred_nb = nb_clf.predict(X_test_scaled)

# Calculate Naive Bayes accuracy
train_accuracy_nb = accuracy_score(y_train, y_train_pred_nb)
test_accuracy_nb = accuracy_score(y_test, y_test_pred_nb)

print(f"Naive Bayes Training Accuracy: {train_accuracy_nb}")
print(f"Naive Bayes Test Accuracy: {test_accuracy_nb}")

# Plotting the accuracies as points
models = ['SVM', 'Naive Bayes']
train_accuracies = [train_accuracy_svm, train_accuracy_nb]
test_accuracies = [test_accuracy_svm, test_accuracy_nb]

# Plotting the accuracies
plt.figure(figsize=(10, 6))
plt.plot(models, train_accuracies, 'o-', label='Training Accuracy', color='blue')
plt.plot(models, test_accuracies, 'o-', label='Test Accuracy', color='red')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison between SVM and Naive Bayes')
plt.legend()
plt.grid(True)
plt.show()

# Bar chart for accuracies
fig, ax = plt.subplots(figsize=(10, 6))
x = np.arange(len(models))
width = 0.35

rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy', color='blue')
rects2 = ax.bar(x + width/2, test_accuracies, width, label='Test Accuracy', color='red')

ax.set_xlabel('Model')
ax.set_ylabel('Accuracy')
ax.set_title('Accuracy Comparison between SVM and Naive Bayes')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

# Attach a text label above each bar
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)

fig.tight_layout()
plt.show()

"""# Thank you"""

# !pip install joblib

import joblib

joblib.dump(model, 'crop recommendation model')

loaded_model = joblib.load('crop recommendation model')













